import{_ as a}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as e,c as r,d as i}from"./app-AuAuVshg.js";const h={},n=i('<h2 id="kafka" tabindex="-1"><a class="header-anchor" href="#kafka" aria-hidden="true">#</a> Kafka</h2><h3 id="不丢失" tabindex="-1"><a class="header-anchor" href="#不丢失" aria-hidden="true">#</a> 不丢失</h3><h4 id="生产者端" tabindex="-1"><a class="header-anchor" href="#生产者端" aria-hidden="true">#</a> 生产者端</h4><ul><li><p>生产者丢失消息是最复杂的情形了。生产者(Producer) 使用 send 方法发送消息实际上是异步的操作，我们可以通过 get()方法获取调用结果，但是这样也让它变为了同步操作，但是一般不推荐这么做！可以采用为其<mark>添加回调函数</mark>的形式。这个回调函数会在 Producer 收到 ack 时调用，此处就和acks参数配置[1、0、-1]密切相关了。设置acks = all，acks是Producer的一个参数，代表了你对已提交消息的定义，如果设置成all，则表明所有副本Broker都要接收到消息，该消息才算是已提交。</p></li><li><p>如果消息发送失败的话，我们检查失败的原因之后重新发送即可！另外这里推荐为 Producer 的 <mark>retries</mark> （重试次数），设置一个比较合理的值，一般是 3 ，但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔 <mark>retry.backoff.ms</mark> ，默认是100ms，可以设置到1秒左右，因为间隔太小的话重试的效果就不明显了，网络波动一次，你3次一下子就重试完了。</p></li></ul><h4 id="消费者端" tabindex="-1"><a class="header-anchor" href="#消费者端" aria-hidden="true">#</a> 消费者端</h4><p>consumer端丢失消息的情形比较简单：如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失。由于Kafka consumer默认是自动提交位移的，所以在后台提交位移前一定要保证消息被正常处理了，因此不建议采用很重的处理逻辑，如果处理耗时很长，则建议把逻辑放到另一个线程中去做。为了避免数据丢失，可以采用手动提交offset：<mark>enable.auto.commit=false</mark> 关闭自动提交位移，在消息被完整处理之后再手动提交位移。</p><h4 id="broker" tabindex="-1"><a class="header-anchor" href="#broker" aria-hidden="true">#</a> Broker</h4><ul><li>设置unclean.leader.election.enable = false，这是Broker端的参数，它控制的是哪些Broker有资格竞选分区的Leader，如果一个Broker落后原先的Leader太多，那么它一旦成为新的Leader，必然会造成消息的丢失，故一般都要将该参数设置成false，即不允许这种情况的发生。</li><li>设置replication.factor &gt;= 3，这也是Broker端的参数，将消息多保存几份，目前防止消息丢失的主要机制就是冗余。</li><li>设置min.insync.replicas &gt; 1，这依然是Broker端参数，控制的是消息至少要被写入到多少个副本才算是已提交，设置成大于1可以提升消息持久性，在实际环境中千万不要使用默认值1。 确保replication.factor &gt; min.insync.replicas，如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了，我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成，推荐设置成replication.factor = min.insync.replicas + 1。</li></ul><h3 id="不重复" tabindex="-1"><a class="header-anchor" href="#不重复" aria-hidden="true">#</a> 不重复</h3><p><strong>消费重复的场景</strong></p><p>在enable.auto.commit 默认值true情况下，出现重复消费的场景有以下几种：</p><h4 id="consumer在消费过程中-应用进程被强制kill掉或发生异常退出" tabindex="-1"><a class="header-anchor" href="#consumer在消费过程中-应用进程被强制kill掉或发生异常退出" aria-hidden="true">#</a> consumer在消费过程中，应用进程被强制kill掉或发生异常退出</h4><p>例如在一次poll 500条消息后，消费到200条时，进程被强制kill消费到offset未提交，或出现异常退出导致消费到offset未提交。 下次重启时，依然会重新拉取500消息，造成之前消费到200条消息重复消费了两次。</p><h5 id="解决方案" tabindex="-1"><a class="header-anchor" href="#解决方案" aria-hidden="true">#</a> 解决方案</h5><p>在发生异常时正确处理未提交的offset</p><h4 id="消费者消费时间过长" tabindex="-1"><a class="header-anchor" href="#消费者消费时间过长" aria-hidden="true">#</a> 消费者消费时间过长</h4><p><mark>max.poll.interval.ms</mark> 参数定义了两次poll的最大间隔，它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起离开组的请求，Coordinator 也会开启新一轮 Rebalance。 举例：单次拉取11条消息，每条消息耗时30s，11条消息耗时5分钟30秒，由于max.poll.interval.ms 默认值5分钟，所以消费者无法在5分钟内消费完，consumer会离开组，导致rebalance。 在消费完11条消息后，consumer会重新连接broker，再次rebalance，因为上次消费的offset未提交，再次拉取的消息是之前消费过的消息，造成重复消费。</p><h5 id="解决方案-1" tabindex="-1"><a class="header-anchor" href="#解决方案-1" aria-hidden="true">#</a> 解决方案</h5><p>1、提高消费能力，提高单条消息的处理速度；根据实际场景可讲max.poll.interval.ms值设置大一点，避免不必要的rebalance；可适当减小<mark>max.poll.records</mark>的值，默认值是500，可根据实际消息速率适当调小。 2、生成消息时，可加入唯一标识符如消息id，在消费端，保存最近的1000条消息id存入到redis或mysql中，消费消息时通过前置去重。</p><h3 id="顺序性" tabindex="-1"><a class="header-anchor" href="#顺序性" aria-hidden="true">#</a> 顺序性</h3><p>我们都知道kafka的topic是无序的，但是一个topic包含多个partition，每个partition内部是有序的</p><h4 id="乱序场景1" tabindex="-1"><a class="header-anchor" href="#乱序场景1" aria-hidden="true">#</a> 乱序场景1</h4><p>因为一个topic可以有多个partition，kafka只能保证partition内部有序</p><h5 id="解决方案-2" tabindex="-1"><a class="header-anchor" href="#解决方案-2" aria-hidden="true">#</a> 解决方案</h5><p>1、<mark>可以设置topic，有且只有一个partition</mark> 2、根据业务需要，需要顺序的指定为同一个partition 3、根据业务需要，比如同一个订单，使用同一个key，可以保证分配到同一个partition上</p><h4 id="乱序场景2" tabindex="-1"><a class="header-anchor" href="#乱序场景2" aria-hidden="true">#</a> 乱序场景2</h4><p>对于同一业务进入了同一个消费者组之后，用了多线程来处理消息，会导致消息的乱序</p><h5 id="解决方案-3" tabindex="-1"><a class="header-anchor" href="#解决方案-3" aria-hidden="true">#</a> 解决方案</h5><p>消费者内部根据线程数量创建等量的内存队列，对于需要顺序的一系列业务数据，根据key或者业务数据，放到同一个内存队列中，然后线程从对应的内存队列中取出并操作 通过设置相同key来保证消息有序性，会有一点缺陷： 例如消息发送设置了重试机制，并且异步发送，消息A和B设置相同的key，业务上A先发，B后发，由于网络或者其他原因A发送失败，B发送成功；A由于发送失败就会重试且重试成功，这时候消息顺序B在前A在后，与业务发送顺序不一致，如果需要解决这个问题，需要设置参数max.in.flight.requests.per.connection=1，其含义是限制客户端在单个连接上能够发送的未响应请求的个数，设置此值是1表示kafka broker在响应请求之前client不能再向同一个broker发送请求，这个参数默认值是5：官方文档说明，这个参数如果大于1，由于重试消息顺序可能重排。</p><h2 id="通用处理方案" tabindex="-1"><a class="header-anchor" href="#通用处理方案" aria-hidden="true">#</a> 通用处理方案</h2><h3 id="不重复-1" tabindex="-1"><a class="header-anchor" href="#不重复-1" aria-hidden="true">#</a> 不重复</h3><h4 id="缓存判重" tabindex="-1"><a class="header-anchor" href="#缓存判重" aria-hidden="true">#</a> 缓存判重</h4><h4 id="业务幂等判断和处理" tabindex="-1"><a class="header-anchor" href="#业务幂等判断和处理" aria-hidden="true">#</a> 业务幂等判断和处理</h4>',33),d=[n];function t(o,c){return e(),r("div",null,d)}const p=a(h,[["render",t],["__file","消息队列常见问题和解决方案.html.vue"]]);export{p as default};
